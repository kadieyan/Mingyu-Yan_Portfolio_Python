# -*- coding: utf-8 -*-
"""Group Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_TgjNKCwPRZAiQCRKzS9jkCdghmo1zbl

# 我的部分是从"Others"到"Elasticity Analysis"

# Data Description

**Context**

The Challenge - One challenge of modeling retail data is the need to make decisions based on limited history. Holidays and select major events come once a year, and so does the chance to see how strategic decisions impacted the bottom line. In addition, markdowns are known to affect sales – the challenge is to predict which departments will be affected and to what extent.

**Content**

You are provided with historical sales data for 45 Walmart stores located in different regions. Each store contains a number of departments, and you are tasked with predicting the department-wide sales for each store.

In addition, Walmart runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, the four largest of which are the Super Bowl, Labor Day, Thanksgiving, and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks. Part of the challenge presented by this competition is modeling the effects of markdowns on these holiday weeks in the absence of complete/ideal historical data.

**Parameters**

Store - the store number

Date - the week

Temperature - average temperature in the region

Fuel_Price - cost of fuel in the region

MarkDown1-5 - anonymized data related to promotional markdowns. MarkDown 
data is only available after Nov 2011, and is not available for all stores all the time. Any missing value is marked with an NA

CPI - the consumer price index

Unemployment - the unemployment rate

IsHoliday - whether the week is a special holiday week

Sales - Historical sales data, which covers to 2010-02-05 to 2012-11-01. Within this tab you will find the following fields:

Dept - the department number

Weekly_Sales -  sales for the given department in the given store


**Holiday**

The four holidays fall within the following weeks in the dataset (not all holidays are in the data):

Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13
Labor Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13
Thanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13
Christmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13

#Data processing
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import calendar  
import random
np.random.seed(42)
from matplotlib import pyplot

"""*Import Data*"""

#mounting drive
from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/'My Drive'/'Retail Analytics'/'S1.csv'
!ls /content/drive/'My Drive'/'Retail Analytics'/'S2.csv'
!ls /content/drive/'My Drive'/'Retail Analytics'/'S3.csv'

features = pd.read_csv("/content/drive/My Drive/Retail Analytics/S1.csv")
sales = pd.read_csv("/content/drive/My Drive/Retail Analytics/S2.csv")
stores = pd.read_csv("/content/drive/My Drive/Retail Analytics/S3.csv")

df=pd.merge(sales,features, on=['Store','Date', 'IsHoliday'], how='left')
df=pd.merge(df,stores, on=['Store'], how='left')
df_raw = df

df['Date'] = pd.to_datetime(df['Date'])

df = df.set_index('Date')

df.describe()

#Mean and SD of each markdown in each month in 2012
Dafr_2012 = df['2012']
DF_2012= Dafr_2012.loc[:,[x for x in Dafr_2012.columns if 'MarkDown' in x]]
Result_2012 = DF_2012.resample('M').agg(['mean','std'])
Result_2012

Dafr_2011 = df['2011']

DF_2011= Dafr_2011.loc[:,[x for x in Dafr_2011.columns if 'MarkDown' in x]]
Result_2011 = DF_2011.resample('M').agg(['mean','std'])
Result_2011

"""# Generate random number for Markdowns"""

# Generate random number for Markdowns in Jan,2010,2011,2012

mean_m11 = Result_2012.iat[0,0]
std_m11 = Result_2012.iat[0,1]
mean_m21 = Result_2012.iat[0,2]
std_m21 = Result_2012.iat[0,3]
mean_m31 = Result_2012.iat[0,4]
std_m31 = Result_2012.iat[0,5]
mean_m41 = Result_2012.iat[0,6]
std_m41 = Result_2012.iat[0,7]
mean_m51 = Result_2012.iat[0,8]
std_m51 = Result_2012.iat[0,9]

Y10_Jan=df['2010-01']
Y11_Jan=df['2011-01']
Y12_Jan=df['2012-01']

Jan = pd.concat([Y10_Jan,Y11_Jan,Y12_Jan], axis=0)
Jan = pd.DataFrame(Jan)
Jan_m= Jan.iloc[:,6:11]


for index, row in Jan_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m11,std_m11)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m21,std_m21)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m31,std_m31)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m41,std_m41)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m51,std_m51)

Jan.iloc[:,6:11]=Jan_m
df['2010-01']=Jan['2010-01']
df['2011-01']=Jan['2011-01']
df['2012-01']=Jan['2012-01']

# Generate random number for Markdowns in Feb,2010,2011,2012

mean_m12 = Result_2012.iat[1,0]
std_m12 = Result_2012.iat[1,1]
mean_m22 = Result_2012.iat[1,2]
std_m22 = Result_2012.iat[1,3]
mean_m32 = Result_2012.iat[1,4]
std_m32 = Result_2012.iat[1,5]
mean_m42 = Result_2012.iat[1,6]
std_m42 = Result_2012.iat[1,7]
mean_m52 = Result_2012.iat[1,8]
std_m52 = Result_2012.iat[1,9]

Y10_Feb=df['2010-02']
Y11_Feb=df['2011-02']
Y12_Feb=df['2012-02']

Feb = pd.concat([Y10_Feb,Y11_Feb,Y12_Feb], axis=0)
Feb = pd.DataFrame(Feb)
Feb_m= Feb.iloc[:,6:11]

for index, row in Feb_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m12,std_m12)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m22,std_m22)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m32,std_m32)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m42,std_m42)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m52,std_m52)

Feb.iloc[:,6:11]=Feb_m
Y10_Feb=Feb['2010-02']
df['2010-02']=Y10_Feb
Y11_Feb=Feb['2011-02']
df['2011-02']=Y11_Feb
Y12_Feb=Feb['2012-02']
df['2012-02']=Y12_Feb

# Generate random number for Markdowns in Mar,2010,2011,2012

mean_m13 = Result_2012.iat[2,0]
std_m13 = Result_2012.iat[2,1]
mean_m23 = Result_2012.iat[2,2]
std_m23 = Result_2012.iat[2,3]
mean_m33 = Result_2012.iat[2,4]
std_m33 = Result_2012.iat[2,5]
mean_m43 = Result_2012.iat[2,6]
std_m43 = Result_2012.iat[2,7]
mean_m53 = Result_2012.iat[2,8]
std_m53 = Result_2012.iat[2,9]

Y10_Mar=df['2010-03']
Y11_Mar=df['2011-03']
Y12_Mar=df['2012-03']


Mar = pd.concat([Y10_Mar,Y11_Mar,Y12_Mar], axis=0)
Mar = pd.DataFrame(Mar)
Mar_m= Mar.iloc[:,6:11]

for index, row in Mar_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m13,std_m13)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m23,std_m23)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m33,std_m33)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m43,std_m43)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m53,std_m53)

Mar.iloc[:,6:11]=Mar_m
Y10_Mar=Mar['2010-03']
Y11_Mar=Mar['2011-03']
Y12_Mar=Mar['2012-03']

df['2010-03']=Y10_Mar
df['2011-03']=Y11_Mar
df['2012-03']=Y12_Mar

# Generate random number for Markdowns in Apr,2010,2011,2012

mean_m14 = Result_2012.iat[3,0]
std_m14 = Result_2012.iat[3,1]
mean_m24 = Result_2012.iat[3,2]
std_m24 = Result_2012.iat[3,3]
mean_m34 = Result_2012.iat[3,4]
std_m34 = Result_2012.iat[3,5]
mean_m44 = Result_2012.iat[3,6]
std_m44 = Result_2012.iat[3,7]
mean_m54 = Result_2012.iat[3,8]
std_m54 = Result_2012.iat[3,9]

Y10_Apr=df['2010-04']
Y11_Apr=df['2011-04']
Y12_Apr=df['2012-04']

Apr = pd.concat([Y10_Apr,Y11_Apr,Y12_Apr], axis=0)
Apr = pd.DataFrame(Apr)
Apr_m= Apr.iloc[:,6:11]

for index, row in Apr_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m14,std_m14)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m24,std_m24)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m34,std_m34)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m44,std_m44)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m54,std_m54)

Apr.iloc[:,6:11]=Apr_m
Y10_Apr=Apr['2010-04']
Y11_Apr=Apr['2011-04']
Y12_Apr=Apr['2012-04']

df['2010-04']=Y10_Apr
df['2011-04']=Y11_Apr
df['2012-04']=Y12_Apr

# Generate random number for Markdowns in May,2010,2011,2012

mean_m15 = Result_2012.iat[4,0]
std_m15 = Result_2012.iat[4,1]
mean_m25 = Result_2012.iat[4,2]
std_m25 = Result_2012.iat[4,3]
mean_m35 = Result_2012.iat[4,4]
std_m35 = Result_2012.iat[4,5]
mean_m45 = Result_2012.iat[4,6]
std_m45 = Result_2012.iat[4,7]
mean_m55 = Result_2012.iat[4,8]
std_m55 = Result_2012.iat[4,9]

Y10_May=df['2010-05']
Y11_May=df['2011-05']
Y12_May=df['2012-05']

May = pd.concat([Y10_May,Y11_May,Y12_May], axis=0)
May = pd.DataFrame(May)
May_m= May.iloc[:,6:11]

for index, row in May_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m15,std_m15)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m25,std_m25)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m35,std_m35)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m45,std_m45)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m55,std_m55)

May.iloc[:,6:11]=May_m
Y10_May=May['2010-05']
Y11_May=May['2011-05']
Y12_May=May['2012-05']

df['2010-05']=Y10_May
df['2011-05']=Y11_May
df['2012-05']=Y12_May

# Generate random number for Markdowns in Jun,2010,2011,2012

mean_m16 = Result_2012.iat[5,0]
std_m16 = Result_2012.iat[5,1]
mean_m26 = Result_2012.iat[5,2]
std_m26 = Result_2012.iat[5,3]
mean_m36 = Result_2012.iat[5,4]
std_m36 = Result_2012.iat[5,5]
mean_m46 = Result_2012.iat[5,6]
std_m46 = Result_2012.iat[5,7]
mean_m56 = Result_2012.iat[5,8]
std_m56 = Result_2012.iat[5,9]

Y10_Jun=df['2010-06']
Y11_Jun=df['2011-06']
Y12_Jun=df['2012-06']

Jun = pd.concat([Y10_Jun,Y11_Jun,Y12_Jun], axis=0)
Jun = pd.DataFrame(Jun)
Jun_m= Jun.iloc[:,6:11]

for index, row in Jun_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m16,std_m16)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m26,std_m26)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m36,std_m36)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m46,std_m46)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m56,std_m56)

Jun.iloc[:,6:11]=Jun_m
Y10_Jun=Jun['2010-06']
Y11_Jun=Jun['2011-06']
Y12_Jun=Jun['2012-06']

df['2010-06']=Y10_Jun
df['2011-06']=Y11_Jun
df['2012-06']=Y12_Jun

# Generate random number for Markdowns in Jul,2010,2011,2012

mean_m17 = Result_2012.iat[6,0]
std_m17 = Result_2012.iat[6,1]
mean_m27 = Result_2012.iat[6,2]
std_m27 = Result_2012.iat[6,3]
mean_m37 = Result_2012.iat[6,4]
std_m37 = Result_2012.iat[6,5]
mean_m47 = Result_2012.iat[6,6]
std_m47 = Result_2012.iat[6,7]
mean_m57 = Result_2012.iat[6,8]
std_m57 = Result_2012.iat[6,9]

Y10_Jul=df['2010-07']
Y11_Jul=df['2011-07']
Y12_Jul=df['2012-07']

Jul = pd.concat([Y10_Jul,Y11_Jul,Y12_Jul], axis=0)
Jul = pd.DataFrame(Jul)
Jul_m= Jul.iloc[:,6:11]

for index, row in Jul_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m17,std_m17)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m27,std_m27)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m37,std_m37)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m47,std_m47)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m57,std_m57)

Jul.iloc[:,6:11]=Jul_m
Y10_Jul=Jul['2010-07']
Y11_Jul=Jul['2011-07']
Y12_Jul=Jul['2012-07']

df['2010-07']=Y10_Jul
df['2011-07']=Y11_Jul
df['2012-07']=Y12_Jul

# Generate random number for Markdowns in Aug,2010,2011,2012

mean_m18 = Result_2012.iat[7,0]
std_m18 = Result_2012.iat[7,1]
mean_m28 = Result_2012.iat[7,2]
std_m28 = Result_2012.iat[7,3]
mean_m38 = Result_2012.iat[7,4]
std_m38 = Result_2012.iat[7,5]
mean_m48 = Result_2012.iat[7,6]
std_m48 = Result_2012.iat[7,7]
mean_m58 = Result_2012.iat[7,8]
std_m58 = Result_2012.iat[7,9]

Y10_Aug=df['2010-08']
Y11_Aug=df['2011-08']
Y12_Aug=df['2012-08']

Aug = pd.concat([Y10_Aug,Y11_Aug,Y12_Aug], axis=0)
Aug = pd.DataFrame(Aug)
Aug_m= Aug.iloc[:,6:11]

for index, row in Aug_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m18,std_m18)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m28,std_m28)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m38,std_m38)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m48,std_m48)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m58,std_m58)

Aug.iloc[:,6:11]=Aug_m
df['2010-08']=Aug['2010-08']
df['2011-08']=Aug['2011-08']
df['2012-08']=Aug['2012-08']

# Generate random number for Markdowns in Sep,2010,2011,2012

mean_m19 = Result_2012.iat[8,0]
std_m19= Result_2012.iat[8,1]
mean_m29 = Result_2012.iat[8,2]
std_m29 = Result_2012.iat[8,3]
mean_m39 = Result_2012.iat[8,4]
std_m39 = Result_2012.iat[8,5]
mean_m49 = Result_2012.iat[8,6]
std_m49 = Result_2012.iat[8,7]
mean_m59 = Result_2012.iat[8,8]
std_m59 = Result_2012.iat[8,9]

Y10_Sep=df['2010-09']
Y11_Sep=df['2011-09']
Y12_Sep=df['2012-09']

Sep = pd.concat([Y10_Sep,Y11_Sep,Y12_Sep], axis=0)
Sep = pd.DataFrame(Sep)
Sep_m= Sep.iloc[:,6:11]


for index, row in Sep_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m19,std_m19)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m29,std_m29)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m39,std_m39)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m49,std_m49)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m59,std_m59)

Sep.iloc[:,6:11]=Sep_m
df['2010-09']=Sep['2010-09']
df['2011-09']=Sep['2011-09']
df['2012-09']=Sep['2012-09']

# Generate random number for Markdowns in Oct,2010,2011,2012

mean_m110 = Result_2012.iat[9,0]
std_m110= Result_2012.iat[9,1]
mean_m210 = Result_2012.iat[9,2]
std_m210 = Result_2012.iat[9,3]
mean_m310 = Result_2012.iat[9,4]
std_m310 = Result_2012.iat[9,5]
mean_m410 = Result_2012.iat[9,6]
std_m410 = Result_2012.iat[9,7]
mean_m510= Result_2012.iat[9,8]
std_m510 = Result_2012.iat[9,9]

Y10_Oct=df['2010-10']
Y11_Oct=df['2011-10']
Y12_Oct=df['2012-10']

Oct = pd.concat([Y10_Oct,Y11_Oct,Y12_Oct], axis=0)
Oct = pd.DataFrame(Oct)
Oct_m= Oct.iloc[:,6:11]


for index, row in Oct_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m110,std_m110)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m210,std_m210)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m310,std_m310)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m410,std_m410)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m510,std_m510)

Oct.iloc[:,6:11]=Oct_m

Y10_Oct=Oct['2010-10']
Y11_Oct=Oct['2011-10']
Y12_Oct=Oct['2012-10']

df['2010-10']=Y10_Oct
df['2011-10']=Y11_Oct
df['2012-10']=Y12_Oct

# Generate random number for Markdowns in Nov,2010,2011,2012

mean_m111 = Result_2012.iat[10,0]
std_m111= Result_2012.iat[10,1]
mean_m211 = Result_2012.iat[10,2]
std_m211 = Result_2012.iat[10,3]
mean_m311 = Result_2012.iat[10,4]
std_m311 = Result_2012.iat[10,5]
mean_m411 = Result_2012.iat[10,6]
std_m411 = Result_2012.iat[10,7]
mean_m511= Result_2012.iat[10,8]
std_m511 = Result_2012.iat[10,9]

Y10_Nov=df['2010-11']
Y11_Nov=df['2011-11']
Y12_Nov=df['2012-11']

Nov = pd.concat([Y10_Nov,Y11_Nov,Y12_Nov], axis=0)
Nov = pd.DataFrame(Nov)
Nov_m= Nov.iloc[:,6:11]

for index, row in Nov_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m111,std_m111)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m211,std_m211)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m311,std_m311)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m411,std_m411)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m511,std_m511)

Nov.iloc[:,6:11]=Nov_m

Y10_Nov=Nov['2010-11']
Y11_Nov=Nov['2011-11']
Y12_Nov=Nov['2012-11']

df['2010-11']=Y10_Nov
df['2011-11']=Y11_Nov
df['2012-11']=Y12_Nov

# Generate random number for Markdowns in Dec,2010,2011,2012

mean_m112 = Result_2011.iat[11,0]
std_m112= Result_2011.iat[11,1]
mean_m212 = Result_2011.iat[11,2]
std_m212 = Result_2011.iat[11,3]
mean_m312 = Result_2011.iat[11,4]
std_m312 = Result_2011.iat[11,5]
mean_m412 = Result_2011.iat[11,6]
std_m412 = Result_2011.iat[11,7]
mean_m512= Result_2011.iat[11,8]
std_m512 = Result_2011.iat[11,9]

Y10_Dec=df['2010-12']
Y11_Dec=df['2011-12']
Y12_Dec=df['2012-12']

Dec = pd.concat([Y10_Dec,Y11_Dec,Y12_Dec], axis=0)
Dec = pd.DataFrame(Dec)
Dec_m= Dec.iloc[:,6:11]

for index, row in Dec_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m112,std_m112)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m212,std_m212)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m312,std_m312)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m412,std_m412)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m512,std_m512)

Dec.iloc[:,6:11]=Dec_m

Y10_Dec=Dec['2010-12']
Y11_Dec=Dec['2011-12']
Y12_Dec=Dec['2012-12']

df['2010-12']=Y10_Dec
df['2011-12']=Y11_Dec
df['2012-12']=Y12_Dec

"""#Visualization"""



df.head()

df_1 = df.sort_values(by=["Date", "Store"])
df_1.head()

df_by_store= df_1.loc[:,[x for x in df_1.columns if 'Store'in x or 'Weekly_Sales'in x or 'Temperature'in x
                           or 'Price'in x or 'MarkDown' in x or 'CPI' in x or 'Unemployment' in x]]
df_by_store= df_by_store.groupby('Store').resample('M').agg({'Weekly_Sales':np.sum,
                                                             'Temperature':np.mean,
                                                             'Fuel_Price':np.mean,
                                                             'MarkDown1':np.sum,
                                                             'MarkDown2':np.sum,
                                                             'MarkDown3':np.sum,
                                                             'MarkDown4':np.sum,
                                                             'MarkDown5':np.sum,
                                                             'CPI':np.mean,
                                                             'Unemployment':np.mean
                                                             })

#Montly data of all stores together
df_allstore = df_by_store.reset_index('Date')
df_allstore = df_allstore.groupby('Date').agg({'Weekly_Sales':np.sum,
                                                             'Temperature':np.mean,
                                                             'Fuel_Price':np.mean,
                                                             'MarkDown1':np.sum,
                                                             'MarkDown2':np.sum,
                                                             'MarkDown3':np.sum,
                                                             'MarkDown4':np.sum,
                                                             'MarkDown5':np.sum,
                                                             'CPI':np.mean,
                                                             'Unemployment':np.mean
                                                             })

#Data Normalization
allstore = df_allstore.apply(lambda x: (x-np.min(x))/(np.max(x)-np.min(x)))
df_s=df_allstore

plt.figure(figsize = (14,8))
sns.set(style='darkgrid', context='notebook', font_scale=1.5, color_codes=True)


x=df_s.index

plt.bar(x, height=df_s['MarkDown1'],color='r',label='MarkDown1',width=30)
plt.bar(x, height=df_s['MarkDown2'],color='b',label='MarkDown2',bottom=df_s['MarkDown1'],width=30)
plt.bar(x, height=df_s['MarkDown3'],color='g',label='MarkDown3',bottom=df_s['MarkDown1']+df_s['MarkDown2'],width=30)
plt.bar(x, height=df_s['MarkDown4'],color='y',label='MarkDown4',bottom=df_s['MarkDown1']+df_s['MarkDown2']+df_s['MarkDown3'],width=30)
plt.bar(x, height=df_s['MarkDown5'],color='c',label='MarkDown5',bottom=df_s['MarkDown1']+df_s['MarkDown2']+df_s['MarkDown3']+df_s['MarkDown4'],width=30)

plt.legend(bbox_to_anchor=(1.3,0.9))
plt.ylabel('Total MarkDown', fontsize=20)
plt.xlabel('Date',fontsize=20)
plt.xticks(x,('2010-01','2010-02','2010-03','2010-04','2010-05','2010-06','2010-07','2010-08','2010-09','2010-10','2010-11','2010-12',
                  '2011-01','2011-02','2011-03','2011-04','2011205','2011-06','2011-07','2011-08','2011-09','2011-10','2011-11','2011-12',
                   '2012-01','2012-02','2012-03','2012-04','2012-05','2012-06','2012-07','2012-08','2012-09','2012-10','2012-11','2012-12'),fontsize=15,rotation=90)
plt.show()

plt.figure(figsize = (15,8))

x =df_s.index 
y=df_s['MarkDown1']
y1=df_s['MarkDown2']
y2=df_s['MarkDown3']
y3=df_s['MarkDown4']
y4=df_s['MarkDown5']


sns.lineplot(x,y,color='r',label='MarkDown1',lw=3)
sns.lineplot(x,y1,color='b',label='MarkDown2',lw=3)
sns.lineplot(x,y2,color='y',label='MarkDown3',lw=3)
sns.lineplot(x,y3,color='g',label='MarkDown4',lw=3)
sns.lineplot(x,y4,color='c',label='MarkDown5',lw=3)

plt.ylabel("MarkDown", fontsize=20, labelpad=15)
plt.xlabel("Date", fontsize=20, labelpad=15)
plt.legend(bbox_to_anchor=(1.0,0.9))
plt.xticks(x,('2010-01','2010-02','2010-03','2010-04','2010-05','2010-06','2010-07','2010-08','2010-09','2010-10','2010-11','2010-12',
                  '2011-01','2011-02','2011-03','2011-04','2011205','2011-06','2011-07','2011-08','2011-09','2011-10','2011-11','2011-12',
                   '2012-01','2012-02','2012-03','2012-04','2012-05','2012-06','2012-07','2012-08','2012-09','2012-10','2012-11','2012-12'),fontsize=15,rotation=90)
plt.show()

plt.figure(figsize = (12,12))

plt.bar(x = df_s.index, height = df_s.Weekly_Sales, width = 31)

plt.xlabel("Date", fontsize=20, labelpad=15)
plt.ylabel("Monthly Sales", fontsize=20, labelpad=15)
plt.xticks(x,('2010-01','2010-02','2010-03','2010-04','2010-05','2010-06','2010-07','2010-08','2010-09','2010-10','2010-11','2010-12',
                  '2011-01','2011-02','2011-03','2011-04','2011205','2011-06','2011-07','2011-08','2011-09','2011-10','2011-11','2011-12',
                   '2012-01','2012-02','2012-03','2012-04','2012-05','2012-06','2012-07','2012-08','2012-09','2012-10','2012-11','2012-12'),fontsize=15,rotation=90)
plt.show()

df_b = df_by_store

df_b = df_b.apply(lambda x: (x-np.min(x))/(np.max(x)-np.min(x)))

plt.figure(figsize = (6,6))

x=df_b['Temperature']
y=df_b['Weekly_Sales']

plt.scatter(x,y)

plt.xlabel('Temperature', fontsize=15)
plt.ylabel('Monthly Sales', fontsize=15)
plt.show()

plt.figure(figsize = (6,6))

x=df_b['CPI']
y=df_b['Weekly_Sales']

plt.xlabel('CPI', fontsize=15)
plt.ylabel('Monthly Sales', fontsize=15)

plt.scatter(x,y)
plt.show()

plt.figure(figsize = (6,6))

x=df_b['Fuel_Price']
y=df_b['Weekly_Sales']

plt.xlabel('Fuel Price', fontsize=15)
plt.ylabel('Monthly Sales', fontsize=15)

plt.scatter(x,y)
plt.show()

fig, axarr = plt.subplots(7, 7, sharex=True, sharey=True,figsize=(15,10))
s = 1
for i in range(0, 7):
    for j in range(0, 7):
        xxx = axarr[i,j].hist(df['Weekly_Sales'].loc[df['Store'] == s], 50);
        axarr[i,j].set_yscale('log')
        axarr[i,j].set_xscale('log')
        axarr[i,j].set_ylim(1,1e4)
        axarr[i,j].set_xlim(5e2,1e6)

        s += 1
fig.text(0.5, 0.04, 'Weekly Sales', ha='center')
fig.text(0.04, 0.5, 'Number', va='center', rotation='vertical')

"""#Others"""

Dafr_2011 = df['2011']

DF_2011= Dafr_2011.loc[:,[x for x in Dafr_2011.columns if 'MarkDown' in x]]
Result_2011 = DF_2011.resample('M').agg(['mean','std'])
Result_2011

"""#Predict Sales - Time Series

**Chain Weekly Sales**
"""

sum_sales = df_raw.groupby(by=['Date'])['Weekly_Sales'].sum()

df_sales = pd.DataFrame(sum_sales)
df_sales = df_sales.reset_index()
df_sales['Date'] = pd.to_datetime(df_sales['Date'])

df_sales.sort_values('Date', inplace=True)

df_sales.set_index(["Date"], inplace=True)

df_sales

max(df_sales['Weekly_Sales'])

plt.figure(figsize = (14,8))
sns.lineplot(df_sales.index,df_sales['Weekly_Sales'],color='c')
plt.ylim(30000000,90000000)

plt.show()

train = df_sales['Weekly_Sales'][0:115]
test = df_sales['Weekly_Sales'][115]

import statsmodels.api as sm
fig = plt.figure(figsize=(12,8))
 
ax1 = fig.add_subplot(211)
fig = sm.graphics.tsa.plot_acf(train, lags=100,ax=ax1)
ax1.xaxis.set_ticks_position('bottom')
fig.tight_layout()
 
ax2 = fig.add_subplot(212)
fig = sm.graphics.tsa.plot_pacf(train, lags=100, ax=ax2)
ax2.xaxis.set_ticks_position('bottom')
fig.tight_layout()
plt.show()

"""**ARIMA**"""

model = sm.tsa.ARIMA(train, order=(1, 0, 1))
results = model.fit()
resid = results.resid 
fig = plt.figure(figsize=(12,8))
fig = sm.graphics.tsa.plot_acf(resid.values.squeeze(), lags=40)
plt.show()

model = sm.tsa.ARIMA(df_sales, order=(1, 0, 1))
results = model.fit()
predict_sunspots = results.predict(start=str('2011-10-14'),end=str('2012-12-10'),dynamic=False)
# print(predict_sunspots)
fig, ax = plt.subplots(figsize=(12, 8))
ax = df_sales.plot(ax=ax)
predict_sunspots.plot(ax=ax)
plt.show()

fore_sunspots = results.forecast(steps=56)[0]

future_date = np.array(range(144,200)).reshape(-1, 1)

df_future_sales = pd.DataFrame(future_date)
df_future_sales.columns = ['Date']
df_future_sales['WeeklySales'] = fore_sunspots


plt.figure(figsize = (14,8))
sns.lineplot(df_future_sales['Date'],df_future_sales['WeeklySales'],color='c')
plt.ylim(30000000,90000000)

plt.show()

"""#Which store has the worst performance"""

store_sales = df_raw.groupby(by=['Store'])['Weekly_Sales'].sum()
store_size = df_raw.groupby(by=['Store'])['Size'].mean()

df_store = pd.concat([store_sales, store_size], axis=1) 
# df_store
for i in range(0,len(df_store['Size'])):
  df_store['Weekly_Sales'][i:i+1] = df_store['Weekly_Sales'][i:i+1] / df_store['Size'][i:i+1]

# df_store

df_store.sort_values('Weekly_Sales', inplace=True)
df_store[0:1]

"""#Conbine Data by "Store" and "Date""""

just_dummies = pd.get_dummies(df_raw['Type'])

df_raw = pd.concat([df_raw, just_dummies], axis=1)  
df_raw.rename(columns={"A": "TypeA","B": "TypeB","C": "TypeC"}, inplace = True)
df_raw = df_raw.drop(['Type'], axis=1)

holiday = np.array(df_raw["IsHoliday"])
holiday_bi = holiday.astype(int)
df_raw["IsHoliday"] = holiday_bi

df_c_1 = df_raw.groupby(by=['Date','Store'])['Weekly_Sales','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5'].sum()
df_c_2 = df_raw.groupby(by=['Date','Store'])["IsHoliday","Temperature","Fuel_Price","CPI","Unemployment","Size","TypeA","TypeB","TypeC"].mean()

df_c = pd.concat([df_c_1, df_c_2], axis=1) 
df_c.swaplevel(0, 1, axis=0)
df_c = df_c.reset_index()

df_c

df_c['Date'] = pd.to_datetime(df_c['Date'])

"""#Correlation Analysis

*Data combined by store and date*
"""

import seaborn as sns

corr_1 = df_c.iloc[:,2:18].corr()
plt.figure(figsize=(15,8))
sns.heatmap(corr_1, 
            annot=True, fmt=".3f",
            xticklabels=corr_1.columns.values,
            yticklabels=corr_1.columns.values,
            cmap="Blues")
plt.show()

"""*raw data but replaced NAN by genarated data*"""

import seaborn as sns

corr = df[['Weekly_Sales','Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5','Size']].corr()
plt.figure(figsize=(15,10))
sns.heatmap(corr, 
            annot=True, fmt=".3f",
            xticklabels=corr.columns.values,
            yticklabels=corr.columns.values,
            cmap="Blues")
plt.show()

"""#Linear Regression"""

df_reg = df_c.drop(df_c[(df_c['MarkDown1']== 0) & (df_c['MarkDown5']== 0) 
& (df_c['MarkDown4']== 0) & (df_c['MarkDown3']== 0) & (df_c['MarkDown2']== 0)].index)

df_reg = df_reg.reset_index()
df_reg = df_reg[['Store','Date','Weekly_Sales','MarkDown1',	'MarkDown2',	'MarkDown3',	'MarkDown4',	'MarkDown5',	'Temperature',	'Fuel_Price',	'CPI',	'Unemployment',	'Size','IsHoliday','TypeA','TypeB','TypeC']]

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler, RobustScaler

robust_scaler_data = preprocessing.RobustScaler().fit(df_reg.iloc[:,3:13])
stdize = robust_scaler_data.transform(df_reg.iloc[:,3:13])

stdize_df = pd.DataFrame(stdize)
sales = df_reg['Weekly_Sales'] / 1000000  # in million $
df_reg = pd.concat([df_reg[['Store','Date']], sales, stdize_df, df_reg[['IsHoliday',	'TypeA','TypeB','TypeC']]], axis = 1)

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression

x_li, y_li = df_reg.iloc[:,3:17], df_reg.iloc[:,2:3]

lin_reg = LinearRegression()

mse_li = cross_val_score(lin_reg, x_li, y_li, scoring = 'neg_mean_squared_error', cv=5)
mean_mse_li = np.mean(mse_li)

print(mean_mse_li)

"""#Ridge regression"""

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Ridge

ridge = Ridge()

parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}

ridge_regressor = GridSearchCV(ridge, parameters, scoring = 'neg_mean_squared_error', cv=5)

ridge_regressor.fit(x_li, y_li)

print(ridge_regressor.best_params_)
print(ridge_regressor.best_score_)

"""#Lasso"""

from sklearn.linear_model import Lasso

lasso = Lasso()

parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}

lasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error', cv=5)

lasso_regressor.fit(x_li, y_li)

print(lasso_regressor.best_params_)
print(lasso_regressor.best_score_)

"""#DNN"""

df_dnn = df_c.drop(df_c[(df_c['MarkDown1']== 0) & (df_c['MarkDown5']== 0) 
& (df_c['MarkDown4']== 0) & (df_c['MarkDown3']== 0) & (df_c['MarkDown2']== 0)].index)

df_dnn = df_dnn.reset_index()
df_dnn = df_dnn[['Store','Date','Weekly_Sales','MarkDown1',	'MarkDown2',	'MarkDown3',	'MarkDown4',	'MarkDown5',	'Temperature',	'Fuel_Price',	'CPI',	'Unemployment',	'Size','IsHoliday','TypeA','TypeB','TypeC']]

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler, RobustScaler

robust_scaler_data = preprocessing.RobustScaler().fit(df_dnn.iloc[:,3:13])
stdize = robust_scaler_data.transform(df_dnn.iloc[:,3:13])

stdize_df = pd.DataFrame(stdize)
sales = df_dnn['Weekly_Sales'] / 1000000  # in million $
df_dnn = pd.concat([df_dnn[['Store','Date']], sales, stdize_df, df_dnn[['IsHoliday',	'TypeA','TypeB','TypeC']]], axis = 1)
# df_dnn

from sklearn.model_selection import train_test_split

x,y = df_dnn.iloc[:,3:17], df_dnn.iloc[:,2:3]

x_train, x_test, y_train, y_test =train_test_split(x, y, test_size=0.2, random_state=42)

import tensorflow as tf
  
dnn = tf.keras.Sequential()
dnn.add(tf.keras.layers.Dense(256, input_shape=(14,), kernel_initializer = 'normal', activation='relu'))
dnn.add(tf.keras.layers.Dense(64, kernel_initializer = 'normal', activation='relu'))
dnn.add(tf.keras.layers.Dense(1, kernel_initializer = 'normal', activation='linear'))
  
dnn.compile(optimizer='adam', loss='mse')

history = dnn.fit(x_train, y_train, validation_data = (x_test, y_test) ,batch_size = 30, epochs = 500, verbose=1)

loss     = history.history[    'loss' ]
val_loss = history.history['val_loss' ]

epochs   = range(len(loss)) # Get number of epochs

plt.plot  ( epochs,     loss )
plt.plot  ( epochs, val_loss )
plt.title ('Training and validation loss'   )

"""#Elasticity Analysis

**Simple Elasticity**
"""

df_e = df_c[(df_c['Temperature'] > 0) & (df_c['MarkDown1'] > 0) & (df_c['MarkDown2'] > 0) & 
            (df_c['MarkDown3'] > 0) & (df_c['MarkDown4'] > 0) & (df_c['MarkDown5'] > 0)]

import math
df_ln = np.log(df_e[['Weekly_Sales','Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size',
                   'MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']])

df_e = pd.concat([df_e[['Date','Store']], df_ln], axis=1) 
df_e = df_e.reset_index()
df_e = df_e.drop('index', axis = 1)
# df_e

from sklearn.linear_model import LinearRegression

X = df_e[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size',
                   'MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']]
y = df_e["Weekly_Sales"]

ela_reg = LinearRegression().fit(X, y)

ela_reg.coef_

ela_reg.intercept_

# ela_reg.score(X, y)

"""**IsHoliday Markdown Elasticity**"""

df_ee = df_c[df_c['IsHoliday'] == 1] 
df_ee = df_ee[(df_c['MarkDown1'] > 0) & (df_c['MarkDown2'] > 0) & 
            (df_c['MarkDown3'] > 0) & (df_c['MarkDown4'] > 0) & (df_c['MarkDown5'] > 0)]

import math
df_ln_e = np.log(df_ee[['Weekly_Sales','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']])

df_ee = pd.concat([df_ee[['Date','Store']], df_ln_e], axis=1) 
df_ee = df_ee.reset_index()
df_ee = df_ee.drop('index', axis = 1)

from sklearn.linear_model import LinearRegression

X_e = df_ee[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']]
y_e = df_ee["Weekly_Sales"]

ela_reg = LinearRegression().fit(X_e, y_e)

ela_reg.coef_

ela_reg.intercept_

"""**NotHoliday Markdown Elasticity**"""

df_en = df_c[df_c['IsHoliday'] == 0] 
df_en = df_en[(df_c['MarkDown1'] > 0) & (df_c['MarkDown2'] > 0) & 
            (df_c['MarkDown3'] > 0) & (df_c['MarkDown4'] > 0) & (df_c['MarkDown5'] > 0)]

import math
df_ln_n = np.log(df_en[['Weekly_Sales','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']])

df_en = pd.concat([df_en[['Date','Store']], df_ln_n], axis=1) 
df_en = df_en.reset_index()
df_en = df_en.drop('index', axis = 1)

from sklearn.linear_model import LinearRegression

X_n = df_en[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']]
y_n = df_en["Weekly_Sales"]

ela_reg = LinearRegression().fit(X_n, y_n)

ela_reg.coef_

ela_reg.intercept_



"""#Prediction"""

!ls /content/drive/'My Drive'/'Retail Analytics'/'forecast_data.csv'

df_future = pd.read_csv('/content/drive/My Drive/Retail Analytics/forecast_data.csv')

df_future = df_future[0:12]
df_future

df_future['date'] = pd.to_datetime(df_future['date'])
df_future = df_future.set_index('date')

mean_m11 = Result_2012.iat[0,0]
std_m11 = Result_2012.iat[0,1]
mean_m21 = Result_2012.iat[0,2]
std_m21 = Result_2012.iat[0,3]
mean_m31 = Result_2012.iat[0,4]
std_m31 = Result_2012.iat[0,5]
mean_m41 = Result_2012.iat[0,6]
std_m41 = Result_2012.iat[0,7]
mean_m51 = Result_2012.iat[0,8]
std_m51 = Result_2012.iat[0,9]

P_Jan = df_future['2013-01']
P_Jan = pd.DataFrame(P_Jan)
P_Jan_m = P_Jan.iloc[:,2:7]

for index, row in P_Jan_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m11,std_m11)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m21,std_m21)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m31,std_m31)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m41,std_m41)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m51,std_m51)

P_Jan.iloc[:,2:7]=P_Jan_m
df_future['2013-01']=P_Jan['2013-01']

mean_m12 = Result_2012.iat[1,0]
std_m12 = Result_2012.iat[1,1]
mean_m22 = Result_2012.iat[1,2]
std_m22 = Result_2012.iat[1,3]
mean_m32 = Result_2012.iat[1,4]
std_m32 = Result_2012.iat[1,5]
mean_m42 = Result_2012.iat[1,6]
std_m42 = Result_2012.iat[1,7]
mean_m52 = Result_2012.iat[1,8]
std_m52 = Result_2012.iat[1,9]

P_Feb=df_future['2013-02']
P_Feb = pd.DataFrame(P_Feb)
P_Feb_m= P_Feb.iloc[:,2:7]

for index, row in P_Feb_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m12,std_m12)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m22,std_m22)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m32,std_m32)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m42,std_m42)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m52,std_m52)

P_Feb.iloc[:,2:7]=P_Feb_m
P_Feb=P_Feb['2013-02']
df_future['2013-02']=P_Feb

mean_m13 = Result_2012.iat[2,0]
std_m13 = Result_2012.iat[2,1]
mean_m23 = Result_2012.iat[2,2]
std_m23 = Result_2012.iat[2,3]
mean_m33 = Result_2012.iat[2,4]
std_m33 = Result_2012.iat[2,5]
mean_m43 = Result_2012.iat[2,6]
std_m43 = Result_2012.iat[2,7]
mean_m53 = Result_2012.iat[2,8]
std_m53 = Result_2012.iat[2,9]

P_Mar=df_future['2013-03']
P_Mar = pd.DataFrame(P_Mar)
P_Mar_m= P_Mar.iloc[:,2:7]

for index, row in P_Mar_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m13,std_m13)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m23,std_m23)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m33,std_m33)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m43,std_m43)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m53,std_m53)

P_Mar.iloc[:,2:7]=P_Mar_m
P_Mar=P_Mar['2013-03']

mean_m112 = Result_2011.iat[11,0]
std_m112= Result_2011.iat[11,1]
mean_m212 = Result_2011.iat[11,2]
std_m212 = Result_2011.iat[11,3]
mean_m312 = Result_2011.iat[11,4]
std_m312 = Result_2011.iat[11,5]
mean_m412 = Result_2011.iat[11,6]
std_m412 = Result_2011.iat[11,7]
mean_m512= Result_2011.iat[11,8]
std_m512 = Result_2011.iat[11,9]

P_Dec = df_future['2012-12']
P_Dec = pd.DataFrame(P_Dec)
P_Dec_m= P_Dec.iloc[:,2:7]

for index, row in P_Dec_m.iterrows():
    if pd.isna(row['MarkDown1']):
        row['MarkDown1']=np.random.normal(mean_m112,std_m112)
    if pd.isna(row['MarkDown2']):
        row['MarkDown2']=np.random.normal(mean_m212,std_m212)
    if pd.isna(row['MarkDown3']):
        row['MarkDown3']=np.random.normal(mean_m312,std_m312)
    if pd.isna(row['MarkDown4']):
        row['MarkDown4']=np.random.normal(mean_m412,std_m412)
    if pd.isna(row['MarkDown5']):
        row['MarkDown5']=np.random.normal(mean_m512,std_m512)

P_Dec.iloc[:,2:7]=P_Dec_m
P_Dec=P_Dec['2012-12']

df_future = df_future.reset_index('date')

df_future['MarkDown1'][df_future['MarkDown1'] < 0 ] = 0
df_future['MarkDown2'][df_future['MarkDown2'] < 0 ] = 0
df_future['MarkDown3'][df_future['MarkDown3'] < 0 ] = 0
df_future['MarkDown4'][df_future['MarkDown4'] < 0 ] = 0
df_future['MarkDown5'][df_future['MarkDown5'] < 0 ] = 0

df_future = df_future[['store','date','Weekly_Sales','MarkDown1',	'MarkDown2',	'MarkDown3',	'MarkDown4',	'MarkDown5',	'Temperature',	'fuel_prcie',	'CPI',	'unemployment',	'Size','IsHoliday','TypeA','TypeB','TypeC']]

robust_scaler_data = preprocessing.RobustScaler().fit(df_future.iloc[:,3:13])
stdize = robust_scaler_data.transform(df_future.iloc[:,3:13])

stdize_future = pd.DataFrame(stdize)
df_future = pd.concat([df_future[['store','date','Weekly_Sales']], stdize_future, df_future[['IsHoliday',	'TypeA','TypeB','TypeC']]], axis = 1)

df_future

future = dnn.predict(df_future.iloc[:,3:17])

df_future['date'] = pd.to_datetime(df_future['date'])
df_future['Weekly_Sales'] = future

df_future[['date','Weekly_Sales']]

plt.figure(figsize = (14,8))
sns.lineplot(df_future['date'],df_future['Weekly_Sales'],color='c')
# plt.ylim(30000000,90000000)

plt.show()